{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mtw0-pnbga3N"
   },
   "source": [
    "# Gradient Descent Method\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Fpr8FhuKv4T"
   },
   "source": [
    "You know that the Ordinary Least Squares (OLS) is trying to **find the optimal parameters that minimize the cost function**. You might have realized that OLS gives you the normal equation (a closed-form solution) for the optimal values of parameters. If you put in the values of $X$ and $y$ in the normal equation and perform some finite number of operations, you will get the optimal values of the parameters **in a single iteration**. This method is a non-iterative approach for optimization. However, you have also learned that this non-iterative method is not possible when\n",
    "  * $X^TX$ is not invertible, .  \n",
    "  * number of features is larger than the number of samples.\n",
    "\n",
    "Moreover, the inverse operation, $(X^TX)^{-1}$ is computationally very expensive. The time complexity of this operation increases significantly with the increase in number of features. So for a large dataset with a large number of features, OLS becomes computationally expensive and infeasible.\n",
    "\n",
    "In this section you will learn about **Gradient Descent**, an iterative approach to find the optimal parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y357uocStJyU"
   },
   "source": [
    "## Iterative Approach for Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GQuUrYTsbDX"
   },
   "source": [
    "Before diving deep into Gradient Descent, let's understand what an iterative approach for optimization actually means. Unlike the OLS, iterative approach finds the optimal parameters in a number of iterations. It uses a random initial guess and a sequence of approximations to find the optimal parameters. Each approximation in the sequence is computed by applying an *update rule* over the approximation of the previous step. Gradient descent is a first order iterative optimization approach *(First order because it uses the first order derivative to find the optimal parameters)*. It is one of the most popular algorithms in the field of machine learning and deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TTmGBG7UOYrO"
   },
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzb7dKesSuYC"
   },
   "source": [
    "Let's start with an example. Suppose there is a valley between two tall hills and you are stuck at the top of a hill. You are trying to get to the valley at the base of the hill but its all foggy and you can't see a thing. What would you do?\n",
    "\n",
    "Well one way is to begin by feeling the ground around you and take steps down in the steepest direction. You take large steps when the slope is steep and small steps when the slope is gradual. If you continue this long enough, you will reach a point on the hill where it is no longer possible to take a step downwards. Using this approach you are likely to reach the base of the hill.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ROI86MFkFJWz"
   },
   "source": [
    "In this analogy, the hills represents the function you are trying to minimize. The valley at the base of the hill represents the minimum point in the function. To minimize the function, we need to take steps proportional to the slope in the steepest direction. For this, the gradient of the function can be used. The gradient of a function at a point,  points towards the direction of the steepest ascent in the function at that point. If we take the negative of the gradient then it will point towards the direction of the steepest descent in the function. The magnitude of the gradient of the function at a point gives the slope of the function at that point. So the gradient descent algorithm takes the steps proportional to the magnitude of the gradient in the direction negative to that of the gradient to find the minimum point in the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qj8_oeiQ1dUq"
   },
   "source": [
    "Well this is probably the most popular example to understand the concept of gradient descent. Now let's look into a more formal explanation of gradient descent and the steps involved in it in an algorithmic way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8zO_pl7Rik9"
   },
   "source": [
    "### Gradient Descent Algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhT0BxvqRpqW"
   },
   "source": [
    "Let's start with how gradient descent minimizes a function in general. Then you can move into the gradient descent for the cost function of linear regression. Suppose you have a multi-variable real-valued function $f:\\mathbb{R}^{n}\\rightarrow \\mathbb{R}$ for which you want to find the input $\\mathbf{x}$ that produces the smallest possible output $f(\\mathbf{x})$. The gradient descent algorithm works in the following steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bN_LT7iSSTm7"
   },
   "source": [
    "Step 1: Initialize the value of ${x}$ randomly\n",
    "\n",
    "Step 2: Calculate the gradient of $f({x})$ with respect to ${x}$ ie.  $\\frac{\\partial\\ f({x})}{\\partial\\ {x}}$\n",
    "\n",
    "Step 3: Update ${x}$ as:\n",
    "\n",
    "$${x} := {x} - \\alpha \\frac{\\partial\\ f({x})}{\\partial\\ {x}}$$\n",
    "\n",
    "$\\hspace{10cm}$ where, $\\alpha$ is the **learning rate** and '$:=$' is assignment operator\n",
    "\n",
    "Step 4: Repeat steps 1, 2 and 3 until the value of $f({x})$ converges to the minimum value.\n",
    "\n",
    "\n",
    "As the function approaches the minimum point, its gradient approaches zero and so the updates don't change $x$ much. At the minimum point of the function,  $\\frac{\\partial\\ f({x})}{\\partial\\ {x}}\\cong0$ and the solution converges at that point after certain number of iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WvqxbmcfxY1j"
   },
   "source": [
    "The function `gradient_descent` finds the optimal value of $x$ that minimizes the function $f(x)$ using gradient descent. It updates the value of $x$ repeatedly using the function's gradient until the gradient becomes very close to zero or the maximum number of iterations is reached. It finally returns the optimal value of $x$, `x_opt` and the number of iterations required to find that value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Fc6-AORJaeDv"
   },
   "outputs": [],
   "source": [
    "def gradient_descent(gradient, x_init, alpha=0.01, max_iters=10000, precision=1e-8):\n",
    "  x = x_init\n",
    "  iteration = 0\n",
    "\n",
    "  while abs(gradient(x)) > precision and iteration < max_iters:\n",
    "    x = x - alpha * gradient(x)\n",
    "    iteration += 1\n",
    "  x_opt = x\n",
    "\n",
    "  return x_opt, iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpmmifFogKYn"
   },
   "source": [
    "### Example:\n",
    "\n",
    "Let's start with a simple example of finding the minimum value of the function $f(x) = x^2 + 3x -5$.\n",
    "\n",
    "The gradient of the function $f(x)$ is $\\frac{df(x)}{dx} = 2x+3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGrsPoAuy-j_"
   },
   "source": [
    "Let's create a function for $f(x)$ and it's gradient $\\frac{df(x)}{dx}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bkzKXUEihyW3"
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "  return x**2 + 3 * x - 5\n",
    "\n",
    "def gradient_f(x):\n",
    "  return 2*x + 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4EP0veNmrQvh"
   },
   "source": [
    "Now let's use Gradient Descent to find the optimal value of ${x}$ that minimizes the function $f({x})$. Let's choose a **random** value, say 2.4 to start with as the initial value of $x$ *ie.* `x_init = 2.4`. The next thing you need to choose is the value of the learning rate. Learning rate remains constant throughout the training process and generally takes small values between 0 and 1. Let's set the value of learning rate to be 0.25 *ie.* `alpha=0.25` for now. You will learn more about the role of learning rate in the coming sections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "executionInfo": {
     "elapsed": 2706,
     "status": "ok",
     "timestamp": 1602747507202,
     "user": {
      "displayName": "Rojen B.N Pradhan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggzj8VqdRTRq7qGxhXZEkej0NHjZ0_6JfVRU8BU=s64",
      "userId": "11019520446215967419"
     },
     "user_tz": -345
    },
    "id": "0LJX3uBoik4V",
    "outputId": "6e016a1d-37db-4792-d2ea-f074b65ed6c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal x: -1.4999999963678419\n",
      "min f(x): -7.25\n",
      "no. of steps: 30\n"
     ]
    }
   ],
   "source": [
    "x_init = 2.4\n",
    "alpha = 0.25\n",
    "\n",
    "x_optimal, steps = gradient_descent(gradient_f, x_init, alpha)\n",
    "print(\"optimal x:\", x_optimal)\n",
    "print(\"min f(x):\", f(x_optimal))\n",
    "print(\"no. of steps:\", steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5kUIf3K80AeH"
   },
   "source": [
    "If you plot the visualization of the working of gradient descent, it looks like the [animation shown](https://drive.google.com/uc?export=view&id=1rmR1S8nIG7cxbOKUxX6GkbYRXIpwuuTT). As you can see, each iteration decreases the value of the function $f(x)$ and brings the value of $x$ closer to the optimal value. At the minimum point in the function, the gradient becomes close to zero and the value of $x$ don't change by much. After some iterations, the value of $x$ finally converges to the optimal values.\n",
    "\n",
    "<figure align=\"center\">\n",
    "\n",
    "<img src=\"https://i.postimg.cc/63cyY9Gb/Gradient-Descent.gif\" height=\"450px\">\n",
    "<figcaption>Figure 1: Gradient Descent</figcaption>\n",
    "</figure>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0TL6XHrGyO_P"
   },
   "source": [
    "*Note: This animation and the ones following is just a representation and does not show all the iterations but some selected ones to give you an idea of how gradient descent actually works.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0hD3UPmmjMf"
   },
   "source": [
    "## Role of Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9TH15ShsEu5"
   },
   "source": [
    "The learning rate $\\alpha$ is a constant term in the gradient descent algorithm. It determines the size of the steps taken while moving towards the minimum of the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZekldQMEs3jo"
   },
   "source": [
    "### Too Small Learning Rate\n",
    "\n",
    "If the value of the learning rate is too small then the algorithm requires more iterations to converge and could get stuck in undesirable local minimum. Let's change the learning rate for the above example from 0.25 to 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "executionInfo": {
     "elapsed": 3335,
     "status": "ok",
     "timestamp": 1602747511422,
     "user": {
      "displayName": "Rojen B.N Pradhan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggzj8VqdRTRq7qGxhXZEkej0NHjZ0_6JfVRU8BU=s64",
      "userId": "11019520446215967419"
     },
     "user_tz": -345
    },
    "id": "PAL7o7AAi_8y",
    "outputId": "b008889f-2d35-411f-9de0-94ccca9a78a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal x: -1.499999995053417\n",
      "min f(x): -7.25\n",
      "no. of steps: 1014\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.01\n",
    "\n",
    "x_optimal, steps = gradient_descent(gradient_f, x_init, alpha)\n",
    "print(\"optimal x:\", x_optimal)\n",
    "print(\"min f(x):\", f(x_optimal))\n",
    "print(\"no. of steps:\", steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b20JPTzBww6G"
   },
   "source": [
    "The [animation shown](https://drive.google.com/uc?export=view&id=1qdz8VK74BMYarGRUETfaFFBq7PEhmBRw) represents the Gradient descent with a learning rate of 0.01.\n",
    "\n",
    "<figure align=\"center\">\n",
    "       <img src=\"https://i.postimg.cc/63cyY9Gb/Gradient-Descent.gif\" height=\"450px\">\n",
    "\n",
    "<figcaption>Figure 2: Gradient Descent with too small learning rate</figcaption>\n",
    "</figure>\n",
    "\n",
    "\n",
    "\n",
    "As you can see the number of steps required has increased significantly from 30 to 1014 when you decrease the learning rate from 0.25 to 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GFjmJec3xVjH"
   },
   "source": [
    "### Too Large Learning Rate\n",
    "\n",
    "If the value of the learning rate is too large then the algorithm may overshoot the minimum point in the function. Due to this overshooting, the algorithm may take even more number of steps to converge or may not converge at all.\n",
    "\n",
    "Let's set the learning rate to 0.99 in the above example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "executionInfo": {
     "elapsed": 2830,
     "status": "ok",
     "timestamp": 1602747511424,
     "user": {
      "displayName": "Rojen B.N Pradhan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggzj8VqdRTRq7qGxhXZEkej0NHjZ0_6JfVRU8BU=s64",
      "userId": "11019520446215967419"
     },
     "user_tz": -345
    },
    "id": "C-Lnn3NVwgvn",
    "outputId": "27f7ce6b-8525-438b-a8c9-6638df75078e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal x: -1.5000000046596569\n",
      "min f(x): -7.25\n",
      "no. of steps: 195\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.95\n",
    "x_optimal, steps = gradient_descent(gradient_f, x_init, alpha)\n",
    "print(\"optimal x:\", x_optimal)\n",
    "print(\"min f(x):\", f(x_optimal))\n",
    "print(\"no. of steps:\", steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OxDHEZLZz4h7"
   },
   "source": [
    "The [animation shown](https://drive.google.com/uc?export=view&id=1gIYcR1dmvhHdUrmFrS1O3-DUWnBb-UfR) represents the Gradient descent with a learning rate of 0.99.\n",
    "\n",
    "<figure align=\"center\">\n",
    "       <img src=\"https://i.postimg.cc/g2cdHvKp/Gradient-Descent-High-LR.gif\" height=\"450px\">\n",
    "       <figcaption>Figure 3: Gradient Descent with a too large learning rate</figcaption>\n",
    "</figure>\n",
    "\n",
    "\n",
    "As you can see the algorithm is often overshooting the minimum point and jumping from one side to the other. However it does converge after some iterations but this may not always be the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6OvALDYervO4"
   },
   "source": [
    "The learning rate is generally constant throughout the training process but there are other techniques called adaptive learning rates that vary the learning rate while training. You can learn about the adaptive learning rates in greater detail in the deep learning courses.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xo6rhj0W5Ynx"
   },
   "source": [
    "## Non-convex functions\n",
    "\n",
    "Till now you have only minimized convex functions using gradient descent .There is only one minimum point in a convex function and it is the global minimum of the function as shown in figure 4 below.\n",
    "\n",
    "<figure align=\"center\">\n",
    "       <img src=\"https://i.postimg.cc/fLvQjgpM/convex-function.png\" height=\"350px\">\n",
    "<figcaption>Figure 4: Convex function</figcaption>\n",
    "</figure>\n",
    "\n",
    "\n",
    "But what if the function is not convex? In such a case, there will be **multiple minimum points** in the function as shown in the figure 5 below. When we run the gradient descent on such non-convex  function, **it might get stuck at the local minimum and never reach the global minimum**. This is one of the biggest disadvantage of the gradient descent algorithm.\n",
    "\n",
    "<figure align=\"center\">\n",
    "<img src=\"https://i.postimg.cc/mkvrKnLK/non-convex-function.png\" height=\"350px\">\n",
    "\n",
    "<figcaption>Figure 5: Non-convex function</figcaption>\n",
    "</figure>\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ai_ml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
