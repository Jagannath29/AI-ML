{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5y8gmuUF1eQn"
      },
      "source": [
        "# Evaluating classifiers\n",
        "\n",
        "In this section, you will learn how to evaluate a classifier's performance. For this purpose, we will first implement logistic regression on a real world data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyNi8WEG3v10"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMlPsNsM3y-b"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IANot_zi_a9g"
      },
      "source": [
        "## Pima Indians Diabetes Dataset\n",
        "  \n",
        "So we just implemented the logistic regression on a small synthetic dataset. But that is rarely the case in reality. Real-world datasets are huge in size with a large number of examples and features.\n",
        "\n",
        "To give you a taste of how logistic regression solves the classification problem in the real world, we will be implementing logistic regression on the [Pima Indian Diabetes Dataset](https://www.kaggle.com/uciml/pima-indians-diabetes-database). This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. We need to predict if a patient has diabetes or not, based on certain diagnostic measurements included in the dataset. This is a subset of a larger database. It contains only the samples of the patients who are females and at least 21 years old of Pima Indian heritage.\n",
        "\n",
        "As we did earlier, we are going to use Scikit-Learn's [`LogisticRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) object to classify the patient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uExecP82SkMV"
      },
      "source": [
        "### Dataset Description\n",
        "\n",
        "The dataset has Number 768 sample records of patients. There are 8 features:\n",
        "\n",
        "\n",
        "- Pregnancies: Number of times pregnant\n",
        "- Glucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "- BloodPressure: Diastolic blood pressure (mm Hg)\n",
        "- SkinThickness: Triceps skin fold thickness (mm)\n",
        "- Insulin: 2-Hour serum insulin (mu U/ml)\n",
        "- BMI: Body mass index (weight in kg/(height in m)^2)\n",
        "- DiabetesPedigreeFunction\n",
        "- Age: Years\n",
        "\n",
        "Using these 8 predictor variables we need to predict the target variable 'Outcome'. It contains binary value: 1 if the patient has diabetes and 0 if the patient doesn't have diabetes.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rxzvwb_sSEL9"
      },
      "source": [
        "### Importing the dataset\n",
        "\n",
        "Let's import the dataset first and have a quick look at it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zWQlOS6dR1S8",
        "outputId": "d8ec96bb-25e8-4983-cde9-75f72daa9087"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = pd.read_csv('https://storage.googleapis.com/codehub-data/1-lv1-2-diabetes.csv')\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl2kxciZSo3n"
      },
      "source": [
        "### Understanding the data distribution\n",
        "\n",
        "We can get some statistical information about each of the columns of dataset using `dataset.describe()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "_8_VwwPGTFxw",
        "outputId": "87dbe5c5-ea8d-4b82-9e85-e6d67ffc0eab"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.845052</td>\n",
              "      <td>120.894531</td>\n",
              "      <td>69.105469</td>\n",
              "      <td>20.536458</td>\n",
              "      <td>79.799479</td>\n",
              "      <td>31.992578</td>\n",
              "      <td>0.471876</td>\n",
              "      <td>33.240885</td>\n",
              "      <td>0.348958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.369578</td>\n",
              "      <td>31.972618</td>\n",
              "      <td>19.355807</td>\n",
              "      <td>15.952218</td>\n",
              "      <td>115.244002</td>\n",
              "      <td>7.884160</td>\n",
              "      <td>0.331329</td>\n",
              "      <td>11.760232</td>\n",
              "      <td>0.476951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.078000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.300000</td>\n",
              "      <td>0.243750</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>30.500000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.372500</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>140.250000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>127.250000</td>\n",
              "      <td>36.600000</td>\n",
              "      <td>0.626250</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>846.000000</td>\n",
              "      <td>67.100000</td>\n",
              "      <td>2.420000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Pregnancies     Glucose  ...         Age     Outcome\n",
              "count   768.000000  768.000000  ...  768.000000  768.000000\n",
              "mean      3.845052  120.894531  ...   33.240885    0.348958\n",
              "std       3.369578   31.972618  ...   11.760232    0.476951\n",
              "min       0.000000    0.000000  ...   21.000000    0.000000\n",
              "25%       1.000000   99.000000  ...   24.000000    0.000000\n",
              "50%       3.000000  117.000000  ...   29.000000    0.000000\n",
              "75%       6.000000  140.250000  ...   41.000000    1.000000\n",
              "max      17.000000  199.000000  ...   81.000000    1.000000\n",
              "\n",
              "[8 rows x 9 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A564AGkSUHMd"
      },
      "source": [
        "You can clearly see the range of values differ very much from one column to the other. The value of the `DiabetesPedigreeFunction` column ranges between 0.078 to 2.42 whereas the value of the `Glucose` column ranges between 0 to 199. It is a good practice to scale the values to a similar range using **Feature Scaling**.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO7RBrocZVO4"
      },
      "source": [
        "### Data Preprocessing\n",
        "Now we will create a feature matrix $\\mathbf{X}$ which contains all the features and their values of all the patients in the dataset. Similarly a label vector $\\mathbf{y}$ which contains the outcome for all the patients in the dataset.\n",
        "\n",
        "We then **split the dataset into training set and test set**. We will train the logistic regression classifier on the training set. And later, we will evaluate its performance on the test set.\n",
        "\n",
        "Finally we will **scale the features** to a similar range.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tg5s72KRZU2t"
      },
      "outputs": [],
      "source": [
        "# Import train_test_split from sklearn.model_selection and StandardScaler from sklearn.preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X = dataset.drop('Outcome', axis=1)\n",
        "y = dataset['Outcome']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgjzEu1-a8kP"
      },
      "source": [
        "### Training the Logistic Regresssion model.\n",
        "\n",
        "**Now comes the important part**. After all the preprocessing, we will finally fit the logistic regression on the dataset. We will use the `logistic_regression` object's [`fit`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.fit) method for training the model as we did earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "ubZqDbN8CJiB",
        "outputId": "0783447c-ef84-4720-8c52-8758f38f44bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "execution_count": 17,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import LogisticRegression from sklearn.linear_model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logistic_regression = LogisticRegression()\n",
        "logistic_regression.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOuQiClZlJZS"
      },
      "source": [
        "### Making Predictions\n",
        "Now that we have a trained logistic regression model, let's use it to predict the class labels for the samples in the test set. We can get the predicted class labels using the [`predict`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict) method of `logistic_regression` object.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "NhyEU4dxMUTL",
        "outputId": "4793e7f9-33da-4ff1-b499-b29d6e23a26c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>231 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0\n",
              "0    0\n",
              "1    0\n",
              "2    0\n",
              "3    0\n",
              "4    1\n",
              "..  ..\n",
              "226  0\n",
              "227  0\n",
              "228  0\n",
              "229  0\n",
              "230  0\n",
              "\n",
              "[231 rows x 1 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = logistic_regression.predict(X_test)\n",
        "pd.DataFrame(y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_Rt605TYon9"
      },
      "source": [
        "# Evaluation metrics\n",
        "\n",
        "Now that we have predicted whether or not the patients in the test set have diabetes, let's evaluate how good is the prediction made by logistic regression. There are several metrics that are used to measure the performance of a classifier. In this unit, we will learn about the following metrics.\n",
        "\n",
        " - Accuracy\n",
        " - Confusion Matrix\n",
        " - Precision\n",
        " - Recall\n",
        " - F1-score\n",
        "\n",
        "All of these metrics are available in Scikit-Learn's [metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) package  for [classification](https://scikit-learn.org/stable/modules/classes.html#classification-metrics).\n",
        "\n",
        "Note: Confusion matrix is not a performance metric in itself but most of the other performance metrics can be derived from the confusion matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5-Zs8xh9O-Q"
      },
      "source": [
        "## Accuracy\n",
        "This is the simplest performance metric for classification models.\n",
        "Accuracy is the fraction of predictions that the classifier predicted correctly.\n",
        "\n",
        "$$\\text{Accuracy} = \\frac{\\text{Number of correct predictions}}{\\text{Total number of predictions}}$$\n",
        "\n",
        "We can calculate the accuracy using the [accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score) function from the [sklearn.metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) module.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Fmc75qaSN7ld",
        "outputId": "e382d42c-d35f-40b7-881f-b701b7f955a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7359307359307359\n"
          ]
        }
      ],
      "source": [
        "# Import accuracy_score from sklearn.metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUfpRfDIRALn"
      },
      "source": [
        "The model predicted approximately 73.59% of the test data correctly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UeTFS9qeaNZ"
      },
      "source": [
        "### Accuracy Paradox\n",
        "\n",
        "Accuracy paradox refers to the inability of accuracy metric to correctly measure the performance in case of skewed classes. Classes are skewed if a large number of examples belong to one class and only a small number of examples belong to the other class.\n",
        "\n",
        "**Example**<br>\n",
        "Consider a problem where the model needs to detect cancer patients. Suppose  it is a very rare type of cancer and only 1% of the tested people can have it. We built a model and found its accuracy to  be 90%. However, if we build a model that simply classifies every test sample as negative, it will have an accuracy of 99%. If we deploy this model in our lab by considering it's accuracy only, this would result in a catastrophe as no any cancer patient would be detected.\n",
        "\n",
        "Thus, at first, we need to check the skewness of the dataset. We can use [`seaborn.countplot`](https://seaborn.pydata.org/generated/seaborn.countplot.html) to see the number of samples in each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "WIorF7CThce1",
        "outputId": "1b9aef53-b3aa-4a22-a689-c6e7b908251c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.countplot('Outcome', data = dataset)\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"No. of patients\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JN0UYrTuDUi"
      },
      "source": [
        "As you can see from the plot above, our dataset is quite skewed. The number of patients that do not have diabetes (0) is double the number of patients that have diabetes (1). This indicates that accuracy alone is not a dependable metric to measure the model's performance. Can you answer why? (Hint: compute the accuracy when our model predicts 0 only.)\n",
        "\n",
        "We can use metrics such as confusion matrix, precision, recall and F1 score in conjunction with accuracy to better evaluate the performance of our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKu7FBj0KoHE"
      },
      "source": [
        "## Confusion Matrix\n",
        "\n",
        "A confusion matrix is a 2d array as shown below. The rows of the matrix represent the instances of the true classes, while the columns represent the instances of predicted classes (or vice versa). That is to say, given a confusion matrix $C$, the entry $c_{i,j}$ is the number of observations known to belong to class $i$ but predicted to be in class $j$.\n",
        "\n",
        "<figure align=\"center\">\n",
        "<!-- <img src=\"https://drive.google.com/uc?export=view&id=1PlxTya5VwsI0kAzhYCbGyrRS1NyN6jj9\" alt=\"Confusion Matrix\" height = \"300\"/> -->\n",
        "<img src=\"https://i.postimg.cc/SsP62Cs4/image.png\" alt=\"Confusion Matrix\" height = \"300\"/>\n",
        "</figure>\n",
        "\n",
        "**TN (True Negative)** is the number of examples that our classifier predicted as negative $(\\hat{y} = 0)$ and are actually negative $(y = 0)$.\n",
        "\n",
        "**FN (False Negative)** is the number of examples that our classifier predicted as negative $(\\hat{y} = 0)$ but are actually positive $(y = 1)$.\n",
        "\n",
        "**TP (True Positive)** is the number of examples that our classifier predicted as positive $(\\hat{y} = 1)$ and are actually positive $(y = 1)$.\n",
        "\n",
        "**FP (False Positive)** is the number of examples that our classifier predicted as positive $(\\hat{y} = 1)$ but are actually negative $(y = 0)$.\n",
        "\n",
        "FP and FN are also called **Type I** and **Type II** error respectively. The diagonal of the confusion matrix contains the TN and TP. These are the values that the classifier got right. So greater the values in the diagonal, better the classifier's performance.\n",
        "\n",
        "We can use the [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) function from the [sklearn.metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) to compute the confusion matrix. The information provided by the confusion matrix is used for the computation of precision and recall."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "dNiWtkC9RN0u",
        "outputId": "0ad3cf28-cfa2-4dc6-89ef-f78fa8f86c70"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Import confusion_matrix from sklearn.metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "labels = y_test.unique()\n",
        "matrix = confusion_matrix(y_test, y_pred, labels=labels, normalize=None)\n",
        "\n",
        "fig,ax = plt.subplots(figsize=(12,4))\n",
        "ax.imshow(matrix, cmap=\"Blues\")\n",
        "t_hold = (matrix.max() - matrix.min()) / 2.\n",
        "for row,col in itertools.product(range(len(labels)), range(len(labels))):\n",
        "    color = \"white\" if matrix[row,col] > t_hold else \"black\"\n",
        "    ax.text(col, row, matrix[row, col], horizontalalignment=\"center\", color=color)\n",
        "tick_marks = np.arange(len(labels))\n",
        "ax.set_title(\"Confusion Matrix\")\n",
        "ax.set_xlabel(\"Predicted\")\n",
        "ax.set_xticks(np.arange(len(labels)))\n",
        "ax.set_xticklabels(labels, rotation=40, ha=\"right\")\n",
        "ax.set_ylabel(\"Actual\")\n",
        "ax.set_yticks(np.arange(len(labels)))\n",
        "ax.set_yticklabels(labels)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWQzQvl0hEva"
      },
      "source": [
        "We can also use the [plot_confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html#sklearn.metrics.plot_confusion_matrix) function from the [sklearn.metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) to display the confusion matrix. Notice any difference between `confusion_matrix` and `plot_confusion_matrix`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "wuTL-BiiSb6a",
        "outputId": "eb7ab3e0-4bde-4bd1-a2db-ed435ce252c1"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATgAAAEKCAYAAACGzUnMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAcL0lEQVR4nO3de7hVVb3/8fdnb+53tiBeADH1eC2MyLykj1kGmr9uJ0urXxctj1ZantTU85z85ckyzczKLFKPVoZ5LW+JpiVkhoq3QEIIA0GQuwjIZe/9/f0x55YFsvdec+21WGtNPq/nmc9ec665xhyLDV/GmGOO8VVEYGaWRw3VroCZWaU4wJlZbjnAmVluOcCZWW45wJlZbjnAmVluOcCZWdVIul7SEknTC45dLukfkp6TdKekQQXvXSBpjqRZksZ1Vr4DnJlV0w3A+K2OPQgcFBFvA14ALgCQdABwEnBg+pmfSmrsqHAHODOrmoiYDKzY6tgDEdGc7v4NGJ6+/hBwc0RsiIgXgTnAIR2V363M9e2SIU2NMWpE92pXwzJ44bk+1a6CZbCetWyMDepKGePe0zeWr2gp6txpz22YAawvODQhIiZkuNwpwG/T17uTBLw2C9Jj7aqpADdqRHcenzSi2tWwDMYNf0e1q2AZTG15oMtlLF/RwuOTRhZ1buOus9dHxNhSriPpv4Bm4KZSPg81FuDMrPYF0EprRa8h6XPACcB7Y/OE+YVAYQtoeHqsXb4HZ2aZBMGmaClqK4Wk8cB5wAcjYl3BW3cBJ0nqKWlPYB/g8Y7KcgvOzDIrVwtO0kTgaGCIpAXARSSjpj2BByUB/C0iTo+IGZJuAZ4n6bp+OaLjKOoAZ2aZBEFLmZZZi4iTt3H4ug7OvwS4pNjyHeDMLLNW6mMdSQc4M8skgBYHODPLK7fgzCyXAthUJ6kOHODMLJMg3EU1s5wKaKmP+OYAZ2bZJDMZ6oMDnJllJFro0nz97cYBzswySQYZHODMLIeS5+Ac4Mwsp1rdgjOzPHILzsxyKxAtdbLSmgOcmWXmLqqZ5VIgNkaHyaxqRn20M82sZiQP+jYUtXWmnbyoJ0qaIalV0titzndeVDOrrJb0Yd/OtiLcwJvzok4HPgpMLjxYSl5Ud1HNLJMI0RLlaRtFxGRJo7Y6NhMgXa680Bt5UYEXJbXlRX2svfLdgjOzzFpRUVuZ7Q68VLBfX3lRzaz2JYMMRYeOIZKeLNjPmvi5SxzgzCyTtkGGIi0rNfHzNjgvqplVXkuoqK3MnBfVzCqrnDMZ2smLugL4MTAUuFfSMxExznlRzWy7aC3fKOq28qIC3NnO+c6LamaVk0y2r4+7Ww5wZpZJIDbVyVQtBzgzyySCsj3oW2kOcGaWUUUe4q0IBzgzyyRwC87McsyDDGaWS4G84KWZ5VOSNrA+Qkd91NLMaogTP5tZTgXlm8lQaQ5wZpaZW3BmlksRcgvOzPIpGWTwVC0zy6Xy5WSoNAc4M8skGWTwPTgzy6l6mclQH7U0s5rRNpOhmK0z7SR+bpL0oKTZ6c/B6XFJ+lGa+Pk5SWM6K98BzswyK1dme7ad+Pl84KGI2Ad4KN0HOI4kD8M+wGnANZ0V7gBnZplEwKbWhqK2zsuKySQ5GAp9CLgxfX0j8OGC47+MxN+AQZJ27ah834Mzs0ySLmrRbaNS8qIOi4hF6evFwLD0dXuJnxfRDgc4M8ssw0yGLuVFjYiQFKV+3gFuK1ecPYKpfxzAoCHNTPjTrDe9//Adg7nl6p2JgN59Wznz0pfY68D1Xbrmxg3i8rNGMvvvfRgwuJkLfzaPXUZsZNoj/bj+O7vRvEl06x588b9f5uB3r+nStWxL3Xu2csXtL9C9R9DYGEy5bxC/umI3Pvi5JXzkC0vZbdQGTnzr21i90v9U2myHx0RekbRrRCxKu6BL0uO1lfhZ0nhJs9JRj/M7/0T1vf8TK7jkprntvj9sxAYuv30OP394Fp86ezFXnTei3XO3tvilHpz773u/6fikiU30G9TCDX+dyUe/uJTrvp3cVhjY1MLFN87l5w/P4tyr5nPZWSOzfyHr0KYN4ryP78MZ79+fM8btz9ijV7PfmLXMeKIf55+0N4tf6lHtKtagpItazFaiu4DPpq8/C/y+4Phn0tHUQ4FXC7qy21Sx/5YkNQJXA8eS9JWfkHRXRDxfqWuWw1sPXdvhX+oD37nujdf7jVnHskXd39h/6PbB/O66ITRvbGC/MWv5yncX0FjEjJbHJg3k019fDMCRJ6zi6v8aTgTs/dbX3zhnj33Xs2F9Axs3iB49S26x25uI9euSX1K3bkFjtyAC/jmjT5XrVdvKlZOhncTPlwK3SDoVmAd8PD39PuB4YA6wDvh8Z+VXst19CDAnIuYCSLqZZBSkpgNcFvdPbOKd73kNgPmze/LI7wdx5e9n0607/PiC4Tx8x2COPXFlp+UsW9ydobttAqCxG/Qd0MLqFY0M3Glz0u6/3DuQvQ963cGtAhoagp/84R/sNmoDd984lFlP9612lWpaMopanrmoHSR+fu82zg3gy1nKr2SA29aIx7u2PknSaSTPtDBy9/q5z/HMo/2YNHEnfvC72QA8PaU/s//ehzOP2xeAjevFoJ2aAfjWKaNYPL8nzZvEkoXdOeN9yTkf/sJSxp209Qj5m/1rVi+uu2Q3vjPxnxX6Nju21lbxpXH703dAMxddO5c99n2debN6V7taNctLlmeQDhlPABg7ulddNE/mPt+LH54zgm//ei4DmtJWVsCxJ67glAvffEvgouv/BST34K742kguv33OFu8P2WUTS19OWnEtzbB2deMb5S59uTsXnzqKc6+az26jNlb0e+3o1q7uxrN/7c87j17tANeJekkbWMlBhswjHvVgyYLuXPyFPTn3R/MYvteGN44ffORrTLl3EKuWJf9nrF7ZyCsLurdXzBYOff9qHry1CYAp9wxi9LtfQ4I1rzby3595C6dcuIgDD1lb/i9jDGzaRN8BSUu7R69Wxhy5mpfm9KpyrWpb2yhqOaZqVVolW3BPAPtI2pMksJ0EfLKC1yuL756xB8891o9XV3TjU+84gP/79cU0Nye/qBM+s5ybrtyF11Y28pMLktjd2C34yf0vsMe/beCz5y3igpP2IiI5/pXvLGDY8E2dXnP8ycu57Kw9+Nzh+9N/UDMXXjMPgLv+dwgvv9iDm36wCzf9YJekfjf/k0FDmiv07Xc8TcM2cc6V82hoDBoEk+8ZzNSHBvKhU5Zw4hmv0DR0Ez97cCaP/2kAPzx3j2pXt2bUy4KXSu7bVahw6Xjgh0AjcH1EXNLR+WNH94rHJxX/2IVV37jh76h2FSyDqS0PsDpWdKlpNXi/neOY6z9W1Ll3HHHNtK486NtVFb0HFxH3kQztmlmO1EL3sxhVH2Qws/riBS/NLNcc4Mwsl/wcnJnlWr08B+cAZ2aZREBzEYtZ1gIHODPLzF1UM8sl34Mzs1wLBzgzy6t6GWSojzuFZlYzIso32V7SVyVNlzRD0tfSY9vMi1oKBzgzy0i0tDYUtXVYinQQ8EWSxXFHAydI2pv286Jm5gBnZplFqKitE/sDUyNiXUQ0A48AH6X9vKiZOcCZWSYZ14MbIunJgu20gqKmA0dK2klSH5J8CyNoPy9qZh5kMLNsIrkPV6R286JGxExJ3wMeANYCzwAtW53TpbyobsGZWWatqKitMxFxXUS8IyKOAlYCL5DmRQXYKi9qZg5wZpZJlGmQAUDSzunPkST3335D+3lRM3MX1cwyK+NC4LdL2gnYBHw5IlZJai8vamYOcGaWWblmMkTEkds4tpxt5EUthQOcmWUS4alaZpZjnmxvZrlVwWR8ZeUAZ2aZBKLVC16aWV7VSQPOAc7MMvIgg5nlWp004RzgzCyzum/BSfoxHcTpiDirIjUys5oWQGtrnQc44MntVgszqx8B1HsLLiJuLNyX1Cci1lW+SmZW6+rlObhOH2aRdJik54F/pPujJf204jUzs9oVRW5VVszTej8ExgHLASLiWeCoSlbKzGpZccuV18JARFGjqBHxkrRFZVvaO9fMdgA10DorRjEB7iVJhwMhqTvwVWBmZatlZjUrIOpkFLWYLurpwJeB3YGXgYPTfTPbYanIrZNSpLPTnKjTJU2U1EvSnpKmSpoj6beSepRay04DXEQsi4hPRcSwiBgaEZ9OF6Qzsx1VGQYZJO0OnAWMjYiDgEbgJOB7wJURsTdJnoZTS61mMaOob5F0t6SlkpZI+r2kt5R6QTPLgfKNonYDekvqBvQBFgHHALel71c8L+pvgFuAXYHdgFuBiaVe0MzqXNuDvsVsHeRFjYiFwPeB+SSB7VVgGrAqTQQNsIDk9lhJihlk6BMRvyrY/7Wkc0u9oJnVv3LkRZU0mCSL/Z7AKpLG0/hy1K9NR3NRm9KXf5B0PnAzSez+BHBfOSthZnWmPKOo7wNejIilAJLuAI4ABknqlrbihgMLS71ARy24aSQBre2b/EfBewFcUOpFzay+lZ5rfgvzgUMl9QFeJ8mk9STwJ+BjJI2qyuRFjYg9Sy3UzHKsTNOwImKqpNuAp4Bm4GlgAnAvcLOkb6fHriv1GkXNZJB0EHAA0Kugcr8s9aJmVs/eGEDosoi4CLhoq8NzgUPKUX6nAU7SRcDRJAHuPuA44C+AA5zZjqpOpmoV85jIx0j6xosj4vPAaGBgRWtlZrWttcityorpor4eEa2SmiUNAJYAIypcLzOrVXlY8LLAk5IGAb8gGVldAzxW0VqZWU0r0yhqxXUa4CLiS+nLn0m6HxgQEc9VtlpmVtPqPcBJGtPRexHxVGWqZGZWHh214K7o4L0gmRBbVi8814dxux1c7mKtgjaOb/f/QatB8ehfylJO3XdRI+I927MiZlYngnJN1ao4J342s+zqvQVnZtaeuu+impm1q04CXDEr+krSpyV9M90fKaks88TMrE7lKC/qT4HDgJPT/deAqytWIzOraYrit2orpov6rogYI+lpgIhY2ZUsN2aWAzkaRd0kqZG0wSlpKDUxjdbMqqUWWmfFKKaL+iPgTmBnSZeQLJX0nYrWysxqW3nSBu4r6ZmCbbWkr0lqkvSgpNnpz8GlVrOYuag3SZpGsmSSgA9HhDPbm+2oynR/LSJmkSSSJ+0lLiRpTJ0PPBQRl6b5YM4HvlHKNYoZRR0JrAPuBu4C1qbHzGxHVf5R1PcC/4yIeSSZtm5Mj3cpL2ox9+DuZXPymV4kKb5mAQeWelEzq28q/i78EElPFuxPiIgJ2zjvJDbnWx4WEYvS14uBYSVVkuK6qG8t3E9XGflSO6ebmRVqNy9qm/SpjA+yjUx9ERFS6R3iYgYZtr7gU8C7Sr2gmeVAebuoxwFPRcQr6f4rknYFSH8uKbWaxSSd+c+C3QZgDPByqRc0szpX/od4T2Zz9xSSe/2fBS6lUnlRC/QveN1Mck/u9lIvaGY5UKYAJ6kvcCxbJpa/FLhF0qnAPODjpZbfYYBLh277R8Q5pV7AzHKoTAEuItYCO211bDnJqGqXdbRkebeIaJZ0RDkuZGb5IDKNolZVRy24x0nutz0j6S7gVmBt25sRcUeF62ZmtahGJtIXo5h7cL2A5SQ5GNqehwvAAc5sR5WDALdzOoI6nc2BrU2dfD0zq4g6iQAdBbhGoB9bBrY2dfL1zKwS8tBFXRQRF2+3mphZ/chBgKuPFe3MbPuKfIyiluU5FDPLoXpvwUXEiu1ZETOrH3m4B2dmtm0OcGaWSzWSErAYDnBmlolwF9XMcswBzszyywHOzHKrTgJc5iXLzWwHl64mUszWGUmDJN0m6R+SZko6rJx5UR3gzCy78uVkuAq4PyL2A0YDM9mcF3Uf4KF0vyQOcGaWmVqL2zosQxoIHAVcBxARGyNiFWXMi+oAZ2aZZeiiDpH0ZMF2WkExewJLgf+V9LSka9McDdsvL6qZ2RayPejbUV7UbiSrhp8ZEVMlXcVW3dHtnhfVzKxM9+AWAAsiYmq6fxtJwCtbXlQHODPLpG0mQ1dHUSNiMfCSpH3TQ+8FnmdzXlTYDnlRzcy2oNayPQh3JnCTpB7AXODzJA2vyudFNTN7kzJOto+IZ4Bt3aOrbF5UM7P2eC6qmeWXA5yZ5ZVbcGaWXw5wZpZLOcmqZWb2Jl7R18zyLeojwjnAmVlmbsHtgLr3bOWKO+bQvUfQ2C2Ycu8gfvX9XRg2YgMXXjOfAYObmf333lx25kiaN3mWXK2YeNnNrFvfndZW0dLawOkXf5j+fdfzzdMfZpcha1i8rB/fuua9rFnXs9pVrQ3OqgWSrgdOAJZExEGVuk4t2bRBnHfiXqxf10hjt+AHv5vDEw/3599PW8odvxjCI78fzFmXLmD8ySu455dDql1dK3D2ZR9g9Zpeb+x/8vhneWrm7ky8bzQnH/8snzz+WSbcdkgVa1hb6mWQoZLNiBuA8RUsvwaJ9esaAejWPWjsHkTA6HevYco9gwB48NbBHDb+1WpW0opw+NvnM+nRfQCY9Og+HDFmXpVrVFvKseDl9lCxFlxETJY0qlLl16qGhuAnk15gt1EbufuGnVg0rydrX22ktUUALFvUnSG7NFe5llYoAi7/+h8g4O5H9ueeR/ajacDrrHi1DwArXu1N04DXq1zLGhJ4kKFY6QqfpwH0ok+Va9N1ra3iS8fuS98BLVx03YuM2Ht9tatknTjru/+HZav6Mqj/63z/nD8wf9HArc5Qvfx73m7qZZCh6ne6I2JCRIyNiLHdyc9N3LWrG3n2r/3Y/x3r6DuwhYbGdP3mXTexbHHV/1+xAstW9QVg1Wu9mfLUHuy351JWrO5N08B1ADQNXMfK13pXs4q1p3xJZyqq6gEuTwY2NdN3QAsAPXq1MuaoNbw0uxfPPtqPI09YBcCxJ67ksUlbtxCsWnr12ETvXhvfeD32wIW8uHAwf316JOOOmA3AuCNm89enR1azmjWlXAtebg9uSpRR07BNnHPVfBoaoKEBJt89kKl/HMC8F3py4TXz+Nx5i5kzvTeTJjZVu6qWGjzwdf7nK38EoLGhlT9O3Ysnpo9g1otDueiMhzn+yFm8srwf37rmmCrXtIZElG3BS0n/Al4DWoDmiBgrqQn4LTAK+Bfw8YhYWVL5UaGbC5ImAkcDQ4BXgIsi4rqOPjNATfEulWWdO9tONo5/Z7WrYBk89eiPeO3VBepKGf0HDY+3H/XVos6dcvd50zpIOtMW4MZGxLKCY5cBKyLiUknnA4Mj4hul1LWSo6gnV6psM6uuCnc/P0TSOIIkL+qfgZICnO/BmVk2AbRGcVvHeVHbSntA0rSC95wX1cyqqDx5UQHeHRELJe0MPCjpH1tcxnlRzWx7K9coakQsTH8uAe4EDsF5Uc2smtQaRW0dliH1ldS/7TXwfmA6zotqZlVTvod4hwF3SoIkFv0mIu6X9ATOi2pm1ZA86Nv1CBcRc4HR2zi+HOdFNbOqqYGVQorhAGdmmZWjBbc9OMCZWTY1MpG+GA5wZpZR+eaiVpoDnJll5y6qmeWSEz+bWa65BWdmuVUf8c0BzsyyU2t99FEd4Mwsm8AP+ppZPonwg75mlmMOcGaWWw5wZpZLvgdnZnlWL6OoXtHXzDKKpItazFYESY2SnpZ0T7q/p6SpkuZI+q2kHqXW1AHOzLIJyhrggK8CMwv2vwdcGRF7AyuBU0utqgOcmWXXWuTWCUnDgQ8A16b7Ao4BbktPuRH4cKnV9D04M8usjM/B/RA4D+if7u8ErIqI5nR/AbB7qYW7BWdm2RXfRW038bOkE4AlETGtUtV0C87MsomAlqJHUTtK/HwE8EFJxwO9gAHAVcAgSd3SVtxwYGGpVXULzsyyK8MgQ0RcEBHDI2IUcBLwcER8CvgT8LH0tC7lRXWAM7PsyjuKurVvAP8paQ7JPbnrSi3IXVQzyyaAMudkiIg/A39OX88FDilHuQ5wZpZRQNTHTAYHODPLJsgyyFBVDnBmlp1XEzGz3HKAM7N86tII6XblAGdm2QRQJ8slOcCZWXZuwZlZPmWaqlVVDnBmlk1A+Dk4M8utMs9kqBQHODPLzvfgzCyXIjyKamY55hacmeVTEC0t1a5EURzgzCybCiyXVCkOcGaWXZ08JuIVfc0skwCiNYraOiKpl6THJT0raYakb6XHnfjZzKok0gUvi9k6tgE4JiJGAwcD4yUdihM/m1k1RUtLUVuHZSTWpLvd0y0oY+JnRQ0N90paCsyrdj0qYAiwrNqVsEzy+jvbIyKGdqUASfeT/PkUoxewvmB/QkRMKCirEZgG7A1cDVwO/C1tvSFpBPCHiDiolLrW1CBDV//ga5WkJzvIDWk1yL+z9kXE+DKW1QIcLGkQcCewX7nKBndRzawGRMQqknyoh5Emfk7fcuJnM6s/koamLTck9QaOBWZSxsTPNdVFzbEJnZ9iNca/s8rbFbgxvQ/XANwSEfdIeh64WdK3gafpQuLnmhpkMDMrJ3dRzSy3HODMLLcc4CpI0nhJs9IpJ+dXuz7WOUnXS1oiaXq162Jd5wBXIemN06uB44ADgJMlHVDdWlkRbgDK9pyXVZcDXOUcAsyJiLkRsRG4GfhQletknYiIycCKatfDysMBrnJ2B14q2F+QHjOz7cQBzsxyywGuchYCIwr2uzTlxMyyc4CrnCeAfdLF+3oAJwF3VblOZjsUB7gKiYhm4CvAJJL5dbdExIzq1so6I2ki8Biwr6QFkkpebNGqz1O1zCy33IIzs9xygDOz3HKAM7PccoAzs9xygDOz3HKAqyOSWiQ9I2m6pFsl9elCWTdI+lj6+tqOFgKQdLSkw0u4xr8kvSn7UnvHtzpnTUfvb+P8/yfpnKx1tHxzgKsvr0fEwWkKtY3A6YVvFiTqyCQivhARz3dwytFA5gBnVm0OcPVrCrB32rqaIuku4HlJjZIul/SEpOck/QeAEj9J16f7I7BzW0GS/ixpbPp6vKSnJD0r6SFJo0gC6dlp6/HINFnI7ek1npB0RPrZnSQ9IGmGpGsBdfYlJP1O0rT0M6dt9d6V6fGHJA1Nj+0l6f70M1MklTXNnOWLk87UobSldhxwf3poDHBQRLyYBolXI+KdknoCj0p6AHg7sC/J2nTDgOeB67cqdyjwC+CotKymiFgh6WfAmoj4fnreb4ArI+IvkkaSzNbYH7gI+EtEXCzpA0AxswBOSa/RG3hC0u0RsRzoCzwZEWdL+mZa9ldIksGcHhGzJb0L+ClJJnSzN3GAqy+9JT2Tvp5Ckm3ocODxiHgxPf5+4G1t99eAgcA+wFHAxDTR7suSHt5G+YcCk9vKioj21kV7H3CA9EYDbYCkfuk1Ppp+9l5JK4v4TmdJ+kj6ekRa1+VAK/Db9PivgTvSaxwO3Fpw7Z5FXMN2UA5w9eX1iDi48ED6D31t4SHgzIiYtNV5x5exHg3AoRGxfht1KZqko0mC5WERsU7Sn4Fe7Zwe6XVXbf1nYNYe34PLn0nAGZK6A0j6N0l9gcnAJ9J7dLsC79nGZ/8GHCVpz/SzTenx14D+Bec9AJzZtiOpLeBMBj6ZHjsOGNxJXQcCK9Pgth9JC7JNA5uT/36SpOu7GnhR0onpNSRpdCfXsB2YA1z+XEtyf+2pNHHKz0la6ncCs9P3fkmyYsYWImIpcBpJd/BZNncR7wY+0jbIAJwFjE0HMZ5n82jut0gC5AySrur8Tup6P9BN0kzgUpIA22YtcEj6HY4BLk6Pfwo4Na3fDLwMvHXAq4mYWW65BWdmueUAZ2a55QBnZrnlAGdmueUAZ2a55QBnZrnlAGdmufX/AbmD1d3O9SaUAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Import plot_confusion_matrix from sklearn.metrics\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "\n",
        "disp = plot_confusion_matrix(logistic_regression,X_test,y_test)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n6vOmZDYvV5"
      },
      "source": [
        "## Precision\n",
        "\n",
        "Precision measures how often the examples predicted as positive by our classifier are actually positive.  \n",
        "\n",
        "$$\\text{Precision} = \\frac{\\text{True Positive}}{\\text{Total number of positives predicted}} = \\frac{TP}{TP+FP}$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBWDCMxQXNNl"
      },
      "source": [
        "Even though we can compute the precision from the confusion matrix, `sklearn` provides an easier way to compute the precision. We can use the [precision_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score) function from the [sklearn.metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) module to directly compute the precision of our logistic regression classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdztdgswXMtp"
      },
      "outputs": [],
      "source": [
        "# Import precision_score from sklearn.metrics\n",
        "\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "precision = precision_score(y_test, y_pred)\n",
        "print(precision)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLDOR1LbYQEx"
      },
      "source": [
        "As you can see, our classifier has a precision of 0.617 which means that among the patients that the classifier predicts as positive only 61.7% are actually positive or have diabetes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SqlF_6ubRBI"
      },
      "source": [
        "## Recall\n",
        "\n",
        "Recall measures how often the examples that are actually positive are predicted as positive by our classifier.\n",
        "\n",
        "$$\\text{Recall} =  \\frac{\\text{True Positive}}{\\text{Total number of actual positives}} = \\frac{TP}{TP + FN}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cupdczg2YNFh"
      },
      "source": [
        "We can calculate the recall from the confusion matrix as well but here we will use the [recall_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score) function from the [sklearn.metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) module to compute the recall of our classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_HuLiznY9mF"
      },
      "outputs": [],
      "source": [
        "# Import recall_score from sklearn.metrics\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "recall = recall_score(y_test, y_pred)\n",
        "print(recall)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVyVvDJUZFwy"
      },
      "source": [
        "The classifier has a recall of 0.625 which means that among the patients that actually have diabetes, the classifier can only identify 62.5% of them. Can you think of the consequences?\n",
        "\n",
        "Hint: Think about the people who have diabetes and don't take any medication as they are incorrectly diagnosed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-0650Ycr1U7"
      },
      "source": [
        "## F1 Score\n",
        "\n",
        "If your classifier needs to have a balance between precision and recall, then you can use the F1 Score. It is calculated as:\n",
        "$$\\text{F1 score} = \\frac{2 \\times \\text{Precision} \\times \\text{Recall}}{\\text{Precision}  + \\text{Recall}}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhRfd4kMbQkN"
      },
      "source": [
        "We can use the [f1_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score) from [sklearn.metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) to compute the F1 score of the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ln7j64Ej6aID"
      },
      "outputs": [],
      "source": [
        "# Import f1_score from sklearn.metrics\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_score = f1_score(y_test, y_pred)\n",
        "print(f1_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
