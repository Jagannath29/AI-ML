{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxWSu45HGlvG"
   },
   "source": [
    "# Nearest Neighbor Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-v-cycC9Iij"
   },
   "source": [
    "## Learning objectives\n",
    "\n",
    "After reading this notebook, students will be able to:\n",
    "\n",
    "- Explain distance and distance metric mathematically,\n",
    "- Exemplify the nearest neighbor (NN)  search in layman terms,\n",
    "- Describe distance metrics like Euclidean distance, Manhattan distance, Mahalanobis distance, and their use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0dCMP50Gp6B"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMP8n_WSipqp"
   },
   "source": [
    "The nearest neighbor problem is defined as follows: Given a set of points in some metric space $(X, D),$ build a data structure that, given any point $q,$ returns a point in $P$ that is closest to $q$(its “nearest neighbor” in $P$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5Cnwo4rmOhA"
   },
   "source": [
    "I will explain this definition with an example of a post office problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Id3i85h4_BF"
   },
   "source": [
    "__Post office problem__\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwDb0MKXMcuu"
   },
   "source": [
    "\n",
    "<center>\n",
    "<img src=\"https://i.postimg.cc/YqRRk2Ng/KD-Tree.png\" height=450/>\n",
    "<figcaption>Figure: Post office problem</figcaption>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzFpmuobPSNq"
   },
   "source": [
    "Say, you are on point (12,9), and you want to send a post office message to your friend. There are several post offices nearby you. Which post office would you choose to send a letter to your friend, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqyYID3YMeOi"
   },
   "source": [
    "__You cannot formulate an answer to the problem without defining the distance between an arbitrary point and your location.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ck4_FQT1ITUd"
   },
   "source": [
    "## Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQpvJ465QLb3"
   },
   "source": [
    "Let $X$ be a set. A function $d : X × X → R$ is called a distance (or\n",
    "dissimilarity) on $X$ if, for all $x,y ∈ X,$ there holds:\n",
    "\n",
    "\n",
    "1. Non-Negativity:  $~~~~~~d(x,y)≥ 0 $\n",
    "    * It means distance between the two points is always positive. For example, the distance between your location and the nearby post office is always positive.\n",
    "2. Identity/Reflexivity: $~~d(x,y) = 0$ iff $ x = y$\n",
    "    * It means distance between two identical points is zero. For example, distance between your location and your location is zero.\n",
    "3. Symmetry:$~~~~~~~~~~~~~d(x,y) = d(y,x)$\n",
    "    * It means distance must remain equal if you calculate it from either point. For example, the distance between your location and the nearby post office is equal to distance between the nearby post office and your position.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCWztIADQLp7"
   },
   "source": [
    "## Measuring Similarity\n",
    "\n",
    "__Distance Metric__\n",
    "\n",
    "\n",
    "In mathematics, a metric or distance function is a function that defines a distance between each pair of point elements of a set.\n",
    "\n",
    "A function is called a distance function or a distance metric if it satisfies:\n",
    "1. Non-Negativity\n",
    "2. Identity\n",
    "3. Symmetry\n",
    "4. [Triangle Inequality:](https://www.onlinemathlearning.com/triangle-inequality.html) $~d(x,y) ≤ d(x,c) + d(c,y)$\n",
    "\n",
    "A distance becomes metric when it follows Triangle Inequality property.\n",
    "\n",
    "* A distance that satisfies 1,3, and 4 but not two is called a pseudometric.\n",
    "\n",
    "* A distance that satisfies 1,2, and 4 but not three is called a quasi-metric.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Moh9G7j8ITUn"
   },
   "source": [
    "Now that you have learned about the condition of distance function let's learn some popular distance function and their use cases, starting with Euclidean distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHfdZINjn4pI"
   },
   "source": [
    "\n",
    "## Euclidean distance\n",
    "\n",
    "Euclidean distance or Euclidean metric is the straight-line distance between two points in Euclidean space.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://i.postimg.cc/521t51DP/Euclidean-distance.png\" height= 450/>\n",
    "<figcaption>Figure: Euclidean Distance of two points</figcaption>\n",
    "</center>\n",
    "\n",
    "In the above figure $x$ and $y$ are two points in 2D eucledean space. Here $x=(x_1,y_1)~~ and ~~y=(x_2,y_2).$\n",
    "\n",
    "\n",
    "The eucledean distance between $x$ and $y$ is given by:\n",
    "\n",
    "$$ d(x,y) =  \\sqrt{ (x_2 - x_1)^2 + (y_2 - y_1)^2}$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "In general,\n",
    "\n",
    "\n",
    "$$  d(x,y) = {(\\sum^n_{i=1}{|x_i- y_i|}^2)}^{1/2}$$\n",
    "\n",
    "\n",
    "\n",
    "__Note:__\n",
    "\n",
    "When comparing distances, it is not necessary to perform the square root operation: the sums of squares can be compared directly.\n",
    "\n",
    "Disadvantage:\n",
    "\n",
    "- It is extremely sensitive to the scales of the variables involved in the dataset.\n",
    "- The Euclidean distance is blind to correlated variables in the dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W5HDB0DgZvaO"
   },
   "source": [
    "_Let's discuss Manhattan distance in detail._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxW3ohJHnyjC"
   },
   "source": [
    "## Manhattan distance\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Manhattan distance is also known as Taxicab distance.\n",
    "It is the distance you would need to walk in a city like Manhattan. You must stay on the street because you can't cut through the buildings.\n",
    "\n",
    "\n",
    "\n",
    "<center>\n",
    "<img src=\"https://i.postimg.cc/hP2Ys15H/manhatten.png\" height= 450/>\n",
    "<figcaption>Fig: Manhattan Distance of two points</figcaption>\n",
    "</center>\n",
    "\n",
    "\n",
    "In the above figure $x$ and $y$ are two points in 2D. Here $x=(x_1,y_1)~~ and ~~y=(x_2,y_2).$\n",
    "\n",
    "The manhattan distance between $x$ and $y$ is given by:\n",
    "\n",
    "$$ d(x,y) =  | (x_2 - x_1) + (y_2 - y_1) |$$\n",
    "\n",
    "In general,\n",
    "\n",
    "\n",
    "$$  d(x,y) = {(\\sum^n_{i=1}{|x_i- y_i|})}$$\n",
    "\n",
    "\n",
    "\n",
    "Disadvantage:\n",
    "\n",
    "* Path is not unique and often contains many turns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjCzEBIYITUv"
   },
   "source": [
    "## Minkowski distance\n",
    "\n",
    "\n",
    "Minkowski distance is a distance on $R^n$ defined, for $x,y ∈$ $R^n$ by\n",
    "\n",
    "$$ d(x,y) = {(\\sum^n_{i=1}{|x_i- y_i|}^p)}^{1/p}$$\n",
    "\n",
    "It defines a distance between two points in the normed vector space(i.e., in a space where distances can be represented as a vector that has a length). It is also considered as the generalization of both Euclidean distance and Manhattan distance.\n",
    "\n",
    "* p = 2, Euclidean distance\n",
    "* p = 1, Manhattan distance\n",
    "* p = $\\infty$, Chebyshev distance\n",
    "\n",
    "\n",
    "The figure below shows the unit circles,the set of all points that are at the unit distance from the centre, with different values of $p.$\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20211201082526/1.PNG\" />\n",
    "<figcaption>Fig: Unit circles with different values of $p$</figcaption>\n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kjweK_9ve-wX"
   },
   "source": [
    "__Note:__\n",
    "\n",
    "Similarly you can define $power(p,r)$ distance as:\n",
    "\n",
    "$$ d(x,y) =  {(\\sum^n_{i=1}{|x_i- y_i|}^p)}^{1/r}$$\n",
    "\n",
    "\n",
    "* The case $p=2$ and $r = 1$ corresponds to the squared Euclidean distance.\n",
    "\n",
    "* for $p = r > 1$ it is the $l_p-metric.$\n",
    "\n",
    "The $power (p,r)-distance$ with $0<p = r<1$ is called fractional $l_p$ distance. It is not a metric because the unit box is not convex. If you have a few observations and the number of a variable is large, you can use this fractional distance on “dimensionality-cursed” data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zaL5oV_uvQTs"
   },
   "source": [
    "## Disadvantage of euclidean distance and Manhatten distance\n",
    "\n",
    "__You should not use the above-defined metric if the units on each coordinate are not the same.__\n",
    "\n",
    "Example:\n",
    "\n",
    "\n",
    "| Area(sq.ft)  |  Price(K)  |\n",
    "| ---  | ---   |\n",
    "| 2424  |  162000  |\n",
    "| 960  |  1265  |\n",
    "| 840  |  89450  |\n",
    "| 1650  |  140600  |\n",
    "\n",
    "\n",
    "\n",
    "| Area(hectare)  |  Price(in M)  |\n",
    "| ---  | ---   |\n",
    "| 0.0225197 |  162  |\n",
    "| 0.00891869  |  1.265  |\n",
    "| 0.00780386  |  89.450  |\n",
    "| 0.015329  |  140.600  |\n",
    "\n",
    "The two tables above show the `area` and `price` of the same entity. Only the units of the features are different.\n",
    "\n",
    "Since both tables represent the same entities, the distance between any two rows should be the same. But Euclidean distance and Manhattan distance give a different value, even though the distances are technically the same in physical space.\n",
    "\n",
    "* The solution could be to normalize the features.\n",
    "\n",
    "---\n",
    "\n",
    "__The euclidean distance is blind to the correlated variable.__\n",
    "\n",
    "| f1 |  f2 | f3|\n",
    "| ---  | ---   |--- |\n",
    "| 45 |  22  | 45|\n",
    "| 12 | 11 | 12|\n",
    "| 88 |  17 | 88|\n",
    "| 79  |  12  | 79|\n",
    "\n",
    "\n",
    "Consider a hypothetical data set containing three features f1, f2, and f3. In this dataset, f1 and f3 are duplicate columns.They have a high correlation. Yet, Euclidean distance has no means of considering that the duplicate column brings no new information and will essentially weigh the copied variable more heavily in its calculations than the other variables.\n",
    "\n",
    "\n",
    "To solve all these scaling and correlation problems,  [Prof. Prasanta Chandra Mahalanobis](https://en.wikipedia.org/wiki/Mahalanobis_distance)  introduced a new distance calculation method, which is known after his name as Mahalanobis Distance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "INWXQ64J7rmD"
   },
   "source": [
    "## Mahalanobis Distance\n",
    "\n",
    "Mahalanobis distance is the distance between a point and a distribution. It is not a distance between two distinct points. Mahalanobis Distance is a generic distance measurement technique that equals to Euclidean distance for uncorrelated variables.\n",
    "\n",
    "Suppose you have two groups of animals like a mountain goat $G_1$ and a normal goat $G_2$. And you want to know how different they are. You want to formulate a hypothesis about a species, its origin, or evolution.\n",
    "You can solve this problem using a measure of divergence or distance between groups in terms of multiple characteristics. You can compare two different groups based on their height, fur length, horn length, tail length, etc. You can use a Mahalanobis distance measure to solve this problem.\n",
    "\n",
    "* If the average of features in a population of two species is large, the population is different else statistically, they are very same.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8AgUF7z7qZ9"
   },
   "source": [
    "\n",
    "<center>\n",
    "\n",
    "![Mahalanobis-Dist](https://i.postimg.cc/qR5R253j/Mahalanobis-Dist.png)\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gj-4ui54FnwX"
   },
   "source": [
    "### Mathematics behind mahananobis distance\n",
    "\n",
    "Mahalanobis distance is:\n",
    "\n",
    "$$d^2 ~~ = $ $ (x - \\mu )^T \\sum ^-~^1~(x - \\mu ) $$\n",
    "\n",
    "Where,\n",
    "\n",
    "* $x$ is a vector of observation(row).\n",
    "* $\\mu$ is a vector of mean of independent variable\n",
    "in each group $G_1$ and $G_2$.\n",
    "* $\\sum$ is a common (nonsingular) covariance matrix of $x$ in each group $G_1$ and $G_2$\n",
    "\n",
    "The above equation is in the quadratic form; in the end, it gives a real number. $\\sum$ is a positive-definite, and hence $d^2$ is a metric.\n",
    "\n",
    "\n",
    "* The Mahalanobis distance takes the covariance among the variables to calculate distance. With this, the problems of scale and correlation that exists in the Euclidean distance are no longer an issue.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oui16977cRg2"
   },
   "source": [
    "<center>\n",
    "\n",
    "Table 1: Covariance Matrix\n",
    "\n",
    "| features  |  x1 | x2| x.| xn|\n",
    "| ---  | ---   | ---| --- | --- |\n",
    "| x1  |  var(x1) | cov(x1,x2)| ......| cov(x1,xn)|\n",
    "| x2  | cov(x2,x1)  | var(x2)| ......| cov(x2,xn)|\n",
    "| ...  | ...  | ...| ......| .....|\n",
    "| xn  | cov(xn,x1)  | cov(xn,x2) | ......| var(xn)|\n",
    "\n",
    "</center>\n",
    "\n",
    "\n",
    "`Table 1` shows covariance matrix $ \\sum $ . It contains variance in diagonal. Get Inverse of Covariance Matrix: $ \\sum $ to calculate Mahalanobis\n",
    "distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7hyElkhcRZ-"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "* For correlated data features, covariance will be high and dividing by a large covariance value will effectively reduce the distance.\n",
    "\n",
    "* If features are not correlated covariance will be small disttance will not reduce much.\n",
    "\n",
    "Therefore it addresses both the problems of scale as well as the correlation of the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mY8let9adAQ3"
   },
   "source": [
    "Computationally Mahalanobis distance :\n",
    "\n",
    "1. Transforms the columns into uncorrelated variables\n",
    "2. Scales the columns to make their variance equal to 1\n",
    "3. Calculates the Euclidean distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_8b9BhffOWY"
   },
   "source": [
    "__Application of Mahalanobis distance__\n",
    "\n",
    "1. Multivariate outlier detection\n",
    "2. Classification Problems\n",
    "3. One-Class Classification\n",
    "\n",
    "Our motive is just to learn Mahalanobis distance. If you want to learn more about application mentioned here click [Mahalonobis Distance – Understanding the math with examples (python).](https://www.machinelearningplus.com/statistics/mahalanobis-distance/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UeAwtvN0cM9o"
   },
   "source": [
    "_Upto now you haved learned different distance metric and how they calcualte distance. Now, let's jump back into post office problem and try to solve it._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6D5C6a8FePfS"
   },
   "source": [
    "\n",
    "<center>\n",
    "<img src=\"https://i.postimg.cc/YqRRk2Ng/KD-Tree.png\" />\n",
    "<figcaption>Figure: Post office problem</figcaption>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_TztJIXx3bp"
   },
   "source": [
    "## Brute-force Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJHqhmFpx74e"
   },
   "source": [
    "In this problem you cannot go through the building that is why you have to use manhattan distance metric to calculate distance between you and the post office."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z5k3t77aQMT6"
   },
   "outputs": [],
   "source": [
    "post_offices_loc = [(6,12), (3,7), (10,10), (8,4), (15,2), (12,11), (14,10)]\n",
    "your_loc = (12,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eq_3hq8WMlWo"
   },
   "source": [
    "The correct answer is (12,11). But how did you calculate this value? A naive approach would be:\n",
    "\n",
    "1. Find the distance from key to every element of P.\n",
    "2. Use this distance value to find the minimum distance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "29bajejuIw0z"
   },
   "outputs": [],
   "source": [
    "# Find distance between points\n",
    "distances=[]\n",
    "for i in range(len(post_offices_loc)):\n",
    "    distances.append(abs((your_loc[0] - post_offices_loc[i][0])) + abs(your_loc[1] - post_offices_loc[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 2839,
     "status": "ok",
     "timestamp": 1601366221173,
     "user": {
      "displayName": "Sweekar Piya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgANwiorrHo3qefxFS1GLFndn9RtbNHPHR_QwHY=s64",
      "userId": "08906404799877415734"
     },
     "user_tz": -345
    },
    "id": "2iN_D268Li4-",
    "outputId": "cb5a7d17-cffd-4a61-d90a-593fd3c13d63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 11, 3, 9, 10, 2, 3]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PpLaxOOkDWti"
   },
   "source": [
    "Let's define a function that finds minimuum value's index from a given list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6MyW-hI4C2QV"
   },
   "outputs": [],
   "source": [
    "def get_indexes_min_value(l):\n",
    "    min_value = min(l)\n",
    "    if l.count(min_value) > 1:\n",
    "        return [i for i, x in enumerate(l) if x == min(l)]\n",
    "    else:\n",
    "        return l.index(min(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g_A1V-E2DEJw"
   },
   "outputs": [],
   "source": [
    "location = get_indexes_min_value(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 1618,
     "status": "ok",
     "timestamp": 1601366245603,
     "user": {
      "displayName": "Sweekar Piya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgANwiorrHo3qefxFS1GLFndn9RtbNHPHR_QwHY=s64",
      "userId": "08906404799877415734"
     },
     "user_tz": -345
    },
    "id": "ayWMe8SUK-yy",
    "outputId": "5af2a35c-7f12-4ab0-fe51-4de48d717e4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_offices_loc[location]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1g6Qq_DIMkEy"
   },
   "source": [
    "In this naive approach, you are doing a linear search and finding the minimum distance to find the nearest neighbor.\n",
    "* You need one loop to find the distance. Therefore, the worst-case time complexity becomes $O(n).$\n",
    "\n",
    "* You need one loop to find minimum distance. You compare values and find minimum distance. Therefore, the worst-case complexity becomes $O(n).$\n",
    "\n",
    "For d- dimensional space Our naive approach results have $O(nd)$ time complexity in the worst case.\n",
    "\n",
    "---\n",
    "\n",
    "This approach is suitable for a small number of datasets. What if there are millions of entries?\n",
    "---\n",
    "\n",
    "\n",
    "<summary>Ans\n",
    "<Details>\n",
    "* If there are millions of entries, our naive approach becomes inefficient. It will take a lot of memory and space. So we need to formulate a new efficient algorithm.\n",
    "</Details>\n",
    "</summary>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEyfx6U4RJCc"
   },
   "source": [
    "__Objective__\n",
    "\n",
    "* Design an algorithm for Nearest neighbour searching that achieves worst case complexity less than $O(nd).$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLdhjQXsHIXz"
   },
   "source": [
    "# Key Takeaways\n",
    "\n",
    "* To find a nearest neighbor you need to define distance.\n",
    "\n",
    "\n",
    "* Distance is non-negative, symmetric and identical.\n",
    "\n",
    "* Euclidean Distance represents the shortest distance between two points\n",
    "\n",
    "* Manhattan Distance is the sum of absolute differences between points across all the dimensions.\n",
    "\n",
    "* Mahalanobis distance is the distance between a point and a distribution. It is not a distance between two distinct point.\n",
    "\n",
    "\n",
    "* Calculating distances in high dimension sometimes makes no sense and it is a challenging work. It is called curse of dimension.\n",
    "\n",
    "* The worst-case time complexity of the brute-force method to find the nearest neighbor is $O(nd).$ Where $n$ is the number of points, and $d$ is the number of dimensions."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
