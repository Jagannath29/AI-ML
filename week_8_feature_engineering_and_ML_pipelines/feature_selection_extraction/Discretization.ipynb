{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "15bvUMAXTH4J"
   },
   "source": [
    "# Discretization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P4-pX5mMTH9t"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UnZOAWK2Teno"
   },
   "source": [
    "Generally there your data has a set of different values for different features. Each of these value mean something under that feature label. For example, you may have a feature called `age`. Under `age` you have values like $10, 11, 14, 18, 19, 20, 28, 32, 45, 54.$ If you look at this data, you can categorize age into different category like youth, adult, old, or in different intervals of age group like $10-20, 20-30, 30-40$ etc. \n",
    "So discreitzation is the categorizing data and replacing the data by the category or interval or even concepts.\n",
    "\n",
    "#### Learning Outcomes\n",
    "1. Understand how you can change different continuous data into discrete groups of data.\n",
    "2. Understand use of histrogram in discretization.\n",
    "3. Understand use of clustering in discretization.\n",
    "4. Understand use of decision tree in discretization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KtMnIzcQTH7A"
   },
   "source": [
    "## Discretization by Histogram Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "86HKsmi1TfFh"
   },
   "source": [
    "As you have seen in earlier chapter how histogram helps in data reduction, the same logic is true for discretization. If we have hundreds of data, then feature `age` also has hundreds of unique values. Generally human age limits to 100 years. Therefore if we categorize based on interval of ten, i.e. `0-10`, `10-20`, ..., `90-100`, then we can change the amount of the data we deal from hundredes to ten category. \n",
    "\n",
    "As you know histogram calls these intervals as buckets, you may different rules to partition data into buckets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uQKTbCzJYEZn"
   },
   "source": [
    "### Equal-width Histogram\n",
    "Equal-width histogram has data partitioned into equal-sized partions. In our above example, the size of interval was `10`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5SYpsmWTYFx_"
   },
   "source": [
    "\n",
    "### Equal-frequency Histogram\n",
    "Equal-frequency histogram has data partitioned into buckets such that each bucket has same number of data samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8eIgFP7wTIAf"
   },
   "source": [
    "## Discretization by Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m-VwFCyRTfeJ"
   },
   "source": [
    "As with data reduction, clustering can also help you in discretization. For any data with numeric attribute (meaning feature having numerical values), clustering partitions the data into groups or clusters. \n",
    "\n",
    "Once we get these clusters, we can replace values with the corresponding cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jKaUd2gyTIDY"
   },
   "source": [
    "## Discretization by Decision Tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g5xk3sLZTf43"
   },
   "source": [
    "You can discretize your data using decision tree classifiers. \n",
    "As decision tree is supervised classification algorithm; to perform discretization you require label information. Say you want to give `loans` based on `age` group. Each person may have different `credit_history`. Using decision tree, you will first divide data based on `age` then based on `credit_history`. This discretization may use different splitting techniques like GINI index, entropy and more.\n",
    "\n",
    "Because of the class information present in the decision tree, the splits will have similar data that are likely to increase classifcation accuracy.\n",
    "\n",
    "Another method used in discretization is _ChiMerge_ which is $\\chi^2$-based method. Here, the merging occurs when two invertals have similar distribution of classes. The approach is bottom-up approach. You find similar neighbours and merge them into larger intervals, recursively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pQcuQTnQYXhE"
   },
   "source": [
    "## Key Takeaways\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3wW9Yws4Yb0K"
   },
   "source": [
    "1. Histogram bins the continuous data into concrete bins.\n",
    "\n",
    "2. Clustering allows you to group similar data into clusters and use cluster centroid as the representation.\n",
    "\n",
    "3. Decision tree allows you to break the data into different groups based on certain label or feature."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "4.4.3. Discretization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
