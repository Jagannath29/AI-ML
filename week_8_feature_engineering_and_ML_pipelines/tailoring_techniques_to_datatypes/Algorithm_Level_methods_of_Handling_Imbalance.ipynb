{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7vo9RjnmcXq"
      },
      "source": [
        "# Algorithm Level Methods of Handling Imbalance\n",
        "\n",
        "\n",
        "The methods we had learned until now were pre-processing data methods. They required a more in-depth knowledge about the used classifier to identify which underlying mechanisms hinder its performance when class is unevenly distributed.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIFXhlFXKWwK"
      },
      "source": [
        "\n",
        "## Drawback of Sampling Methods\n",
        "\n",
        "There is one drawback of sampling techniques, which is that one needs to determine how much sampling to apply. While using the oversampling technique, one must choose it to promote the minority class while adding overfitting to the given data. Similarly, an under-sampling level must be chosen so as to retain as much information about the majority class as possible while promoting a balanced class distribution.\n",
        "\n",
        "Wrapper methods are developed to solve this problem. The training data is split into a training set and a validation set. For different sampling levels, classifiers are learned on the training set. The performance of each of the learned models is then tested with the validation set. The sampling method with the best performance is used to sample the entire dataset. For hybrid techniques, such wrapper becomes very complicated, as instead of optimizing a single over/under-sampling level, one has to optimize a combination of over/under-sampling levels. So we turn to skew insensitive classifier, i.e., Cost-sensitive classifier.\n",
        "Now you will sneak peek into some of the algorithm level methods of handling imbalance data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeKfXRIGmtT5"
      },
      "source": [
        "## Threshold Method\n",
        "\n",
        "\n",
        "Many Machine Learning algorithms predict a probability or scoring of class membership, which must be interpreted before it can be mapped to a crisp class label. We achieve this by using a threshold, mostly 0.5, where all values equal to or greater than the threshold are mapped to one class, and all other costs are mapped to another category.\n",
        "\n",
        "But things don't remain the same for imbalanced datasets. Same threshold as earlier results unsatisfactory result. So, a simple and straightforward approach to improve the performance of a classifier that predicts probabilities on an imbalanced dataset or classification is to fine-tune the threshold used to map expectations to class labels.\n",
        "\n",
        "The optimal threshold for the classifier can be calculated directly using ROC Curves and Precision-Recall Curves. Also, we can use a grid search to tune the threshold and locate the optimal value for the limit.\n",
        "\n",
        "There is a parameter as \"*decision threshold*,\" which governs the decision for converting a predicted probability into a class label. The default value is 0.5, and tuning this parameter is called **threshold moving**.\n",
        "\n",
        "Always using the default value for the threshold is not appropriate due to few reasons as:\n",
        "\n",
        "- There may be an uneven distribution of the data, i.e., the class distribution may be skewed in nature.\n",
        "- The cost of one type of misclassification may be more important than another type of misclassification.\n",
        "\n",
        "So, in imbalanced datasets, using the classifiers produced by standard machine learning algorithms without adjusting the output threshold may be a critical and crucial mistake.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FHCWCFFmtPh"
      },
      "source": [
        "## One Class Learning\n",
        "\n",
        "\n",
        "One class classification or learning algorithm provides the techniques for outlier and anomaly detection.\n",
        "\n",
        "This type of learning is done in the absence of counterexamples for the scenarios in which during the training step, we have access only to objects coming from a single class.\n",
        "\n",
        "In cases, when we have a minority class which is highly underrepresented, training a binary course is obviously tricky. Instead, we may train a one-class classifier on the majority class and treat the remaining one as outliers. We can use this approach in imbalanced dataset scenarios, where a negative or majority level can be considered as target class and minority or positive class as noise or outliers. This kind of approach is best suited, mainly when the minority class lack any structure, is predominantly composed of small disjuncts or noisy instances.\n",
        "\n",
        "One class classifiers are skew insensitive, as it utilizes one class only during training and creates its data description.\n",
        "\n",
        "There is one problem regarding the presence of sub-concepts or class disjuncts within both majority and minority classes. This, combined with limited learning from minority classes, is the source of significant learning difficulty for many classifiers. Decision boundary becomes too complex, and generalization capabilities are lost, or minority sub-concepts are ignored due to not providing enough information. An ensemble approach for one class classifiers is able to automatically identify these sub-concepts in all of the supplied classes, regardless of their imbalanced ratio.\n",
        "\n",
        "Support Vector Machine, or SVM, which is used initially for binary classification, can be used for one-class learning. When modeling one class, the algorithm captures the density of the majority class and classifies examples on the extremes of the density function as outliers. One class SVM is this modification to SVM.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8by0MXL2mtMs"
      },
      "source": [
        "## Cost Sensitive Learnng\n",
        "\n",
        "\n",
        "Here, in cost insensitive learning instead of each instance being either correctly or incorrectly classified, each instance is given misclassification cost. So, instead of trying to optimize the accuracy, the main problem is to minimize the total misclassification cost then. We use many traditional methods, such as Support Vector Machines (SVMs) with some modifications to follow the cost-sensitive framework.\n",
        "\n",
        "Usually, we assume all the misclassification errors made by a model are equal, but this is not the case for imbalanced classification problems where missing a positive or minority class is worse than incorrectly classifying an example from the negative or majority class. This takes the costs of prediction errors into account when training a machine learning model. Machine Learning algorithm needs to be sensitive to the cost that it is dealing with, and in the better case, take the cost into account. There is a penalty associated with an incorrect prediction and is referred to as \"cost.\" This type of learning is focused on first assigning different costs to the types of misclassification errors that can be made, then using specialized methods to take these costs into account.\n",
        "\n",
        "To see how this happens , consider a problem of learning SVM. SVMs attempt to learn a weight vector that satisfies the following optimisation problem:\n",
        "\n",
        "$$\n",
        "min_{w, \\xi , b}\\left \\{ \\frac{1}{2}\\left \\| w \\right \\|^2 + C\\sum_{i=1}^{n} \\xi_i\\right \\}\n",
        "$$\n",
        "\n",
        "Where $\\xi_i$ denotes the \"slack\" for instance, $i$ (I.e., how badly misclassified, if at all, the instance is by w) and C determines the trade-off between training error and model complexity.\n",
        "\n",
        "\n",
        "In order to make SVMs cost sensitive, the objective function is modified resulting in:\n",
        "\n",
        "$$\n",
        "min_{w, \\xi , b}\\left \\{ \\frac{1}{2}\\left \\| w \\right \\|^2 + C\\sum_{i=1}^{n} c_i\\xi_i\\right \\}\n",
        "$$\n",
        "\n",
        "where $c_i$, is the, misclassification cost for instance $i$.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAR7dlojf85a"
      },
      "source": [
        "Out of three algorithmic techniques, you will see cost sensitive learning being used in the implementation section in Chapter 6."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvgHn3z4mtKH"
      },
      "source": [
        "## Key Takeaways\n",
        "This chapter discussed algorithm-level solutions for class imbalance as an alternative to pre-processing data approaches.\n",
        "\n",
        "Tuning the decision threshold to accommodate the broader requirements of the classification problem refers to “threshold-moving,” “threshold-tuning,” or simply “thresholding.”\n",
        "\n",
        "\n",
        "One-class classifier aims at capturing characteristics of training instances to be able to distinguish between them and potential outliers, anomalies, or noises to appear.\n",
        "\n",
        "Cost-sensitive learning is a subfield that involves explicitly defining and using costs when training machine learning algorithms.\n",
        "\n",
        "Although many algorithmic methods have been introduced, new challenges lie ahead. Proposing ways that are able to combine pre-processing and algorithm-level solutions in a guided manner seem like a highly attractive direction.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3za5kYN4VRV"
      },
      "source": [
        "## References\n",
        "\n",
        "- [Imbalanced Learning: Foundations, Algorithms, and Applications](https://www.amazon.com/dp/1118074629/ref=as_li_ss_tl?&linkCode=sl1&tag=inspiredalgor-20&linkId=615e87a9105582e292ad2b7e2c7ea339&language=en_US), 2013.\n",
        "- [Learning from Imbalanced Data Sets](https://www.amazon.com/Learning-Imbalanced-Data-Alberto-Fern%C3%A1ndez/dp/3319980734/ref=as_li_ss_tl?keywords=Learning+from+Imbalanced+Data+Sets&qid=1568679479&s=books&sr=1-1&linkCode=sl1&tag=inspiredalgor-20&linkId=214f8d8144c94e7f48543e0200abdbdf&language=en_US), 2018."
      ]
    }
  ]
}